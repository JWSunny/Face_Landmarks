主要是关于人脸中关键点定位的方法Deep Alignment Network:

1.包括模型介绍及相关的code implementation
2.设计的一些知识点的理解说明；

dataset：
1.论文主要研究关于人脸68关键点【人脸对齐】；
2.常见的数据集LFPW, HELEN, AFW, IBUG, 300W；
3.共3148张图片，其中选取3048张图，进行镜像、平移、旋转和缩放操作，生成60000多图片；

改进：
1.【后期加入了Menpo challenge data数据集】，其中包括部分正脸和侧脸的情形； 6600张左右的训练图片 和 5300左右的测试图片；标注规则和300W一致；
2.对应日常场景遮挡的情形，可以增加随机遮挡；（https://github.com/isarandi/synthetic-occlusion#getting-started）

PrepareData：【数据集的一些处理】
1.首先是常见的一些数据增强的处理方法，包括平移，翻转或者旋转等操作；其中，仿射变换也是常用到的；
仿射变换： 线性变换 + 平移操作； 主要通过变换前后，选择对应的三个变换的点坐标，得到变换矩阵，从而将图片仿射变换到方形图片中；
仿射变换在图像中常常用到，一般深度学习模型需要固定的输入尺度，所以一般在做人脸对齐或者人体姿态估计时，深度学习模型常需要方形的图片尺寸；


DAN论文相关介绍：【原始论文地址： https://arxiv.org/abs/1706.01789 】
1.网络的输入可以是整张图片，且是分阶段进行训练的；
2.关键点热图是论文的主要创新点；
3.主要目的是实现人脸对齐，即人脸的68关键点的定位；

细节说明：
1.模型是分阶段进行训练，尝试训练2个阶段；
2.阶段1：【主要包括 feed-forward neural network 和 transform estimation layer】
【model_stage1.py 中实现阶段1中，关于 feed-forward neural network】

输入：原始图片（灰度图），及平均的人脸中的68关键点坐标S0；
输出：面部的68关键点的位置；

3.阶段2：
输入： 与规范坐标对其的 image进行变换，landmark heatmap 和 阶段1最后全连接的输出；

原图的image变换： 其实就是将原图进行矫正，对齐；
heatmap：关键点热图的计算其实是一个中心衰减，关键点处值越大，越远值越小；【论文公式1】
阶段1：fc1层输出的特征；

上述三者的所有特征进行融合，输入到第2阶段的网络；【具体实现查看 model_stage2.py】

输出： 对第2阶段的输出值，进行 transform的反变换操作， 即对应原始图片预测的landmarks；【论文公式2】

4.论文中同时证明：两个stage的训练效果最佳，当 N 大于2之后，误差值和最终的AUC值是降低的；


文中涉及的部分重要点说明：
1.主要是 阶段1 和 阶段2 的 feed-forward network，上述已经进行相关实现，涉及卷积层、批归一化、池化层和dropout层；激活函数采用relu；
2.每个阶段回归的其实是关键点坐标的相对偏差值（残差的思想）；阶段2得到最终的预测坐标，通过反变换，得到在初始阶段1图片中关键点的坐标；【论文公式2】
3.关于损失计算，68关键点当做回归问题来解决，计算 预测坐标与gt坐标的均方根误差值；【论文中进行了误差的归一化操作（相对于瞳孔间距、外眼角间距或者bounding box对角线的比值）】
4.阶段2中涉及的图像变换操作，主要实现的效果就是将人脸进行对齐操作；（主要采用的是相似变换操作和线性插值的方法）
模板landmarks 和 阶段1的输出坐标 得到相似变换矩阵；
图片进行相应的变换操作及线性插值将人脸对齐；
关键点也进行对齐，并获取关键点热图； 同时获取前一阶段fc1的特征图；三者进行融合，作为下一阶段的输入特征；

等距变换：是旋转变换 和 平移变换的复合操作
相似变换： 是等距变换 和 均匀缩放的复合操作；
关键点的这边使用的变换是 相似变换，相比于仿射变换效果更不易造成图像变形；
